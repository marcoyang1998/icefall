#!/usr/bin/env bash

# fix segmentation fault reported in https://github.com/k2-fsa/icefall/issues/674
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

set -eou pipefail

nj=15
stage=0
stop_stage=100

# Split XL subset to a number of pieces (about 2000)
# This is to avoid OOM during feature extraction.
num_per_split=20000

dl_dir=$PWD/download
fbank_dir=data/fbank_gigaspeech
manifest_dir=data/manifests

. shared/parse_options.sh || exit 1

# vocab size for sentence piece models.
# It will generate data/lang_bpe_xxx,
# data/lang_bpe_yyy if the array contains xxx, yyy
vocab_sizes=(
  500
)

# All files generated by this script are saved in "data".
# You can safely remove "data" and rerun this script to regenerate it.
mkdir -p data

log() {
  # This function is from espnet
  local fname=${BASH_SOURCE[1]##*/}
  echo -e "$(date '+%Y-%m-%d %H:%M:%S') (${fname}:${BASH_LINENO[0]}:${FUNCNAME[1]}) $*"
}

log "dl_dir: $dl_dir"

if [ $stage -le 0 ] && [ $stop_stage -ge 0 ]; then
    log "Stage 0: untar the gigaspeech dataset"
    # for subset in dev test xs; do
    #     log "Start untarring ${subset}"
    #     n_archives=$(cat $dl_dir/gigaspeech/data/${subset}_n_archives.txt)
    #     tar_folder=${dl_dir}/gigaspeech/data/audio/${subset}_files
    #     if [ ! -d $tar_folder/.untar.done ]; then
    #         tar_files=$(find $tar_folder -name "*.tar.gz")
    #         count=$(find $tar_folder -name "*.tar.gz" | wc -l)
    #         # find $tar_folder -name "*.tar.gz" | xargs tar -xf
    #         log "Finding $count tar.gz files"
    #         for tar_file in $tar_files; do
    #             tar_out=$(echo $tar_file | sed "s/.tar.gz//g")
    #             if [ ! -d $tar_out ]; then
    #                 tar -xf $tar_file -C $tar_folder
    #                 log "Untarred $tar_file"
    #             fi
    #         done
    #         touch $tar_folder/.untar.done
    #     fi
    #     log "Finish untarring ${subset}"
    # done

    for subset in xl; do
        log "Start untarring ${subset}"
        n_archives=$(cat $dl_dir/gigaspeech/data/${subset}_n_archives_additional.txt)
        tar_folder=${dl_dir}/gigaspeech/data/audio/${subset}_files_additional
        
        if [ ! -d $tar_folder/.untar.done ]; then
            tar_files=$(find $tar_folder -name "*.tar.gz")
            count=$(find $tar_folder -name "*.tar.gz" | wc -l)
            # find $tar_folder -name "*.tar.gz" | xargs tar -xf
            log "Finding $count tar.gz files"
            for tar_file in $tar_files; do
                tar_out=$(echo $tar_file | sed "s/.tar.gz//g")
                if [ ! -d $tar_out ]; then
                    tar -xf $tar_file -C $tar_folder
                    log "Untarred $tar_file"
                fi
            done
            touch $tar_folder/.untar.done
        fi
        log "Finish untarring ${subset}"
    done
fi

if [ $stage -le 1 ] && [ $stop_stage -ge 1 ]; then
    log "Stage 1: create the manifest"
    for subset in xl; do
        log "Start generating ${subset} manifests"
        if [ ! -f $manifest_dir/.${subset}.done ]; then
            python local/prepare_hf_gigaspeech.py \
                --dataset-dir $dl_dir/gigaspeech \
                --subset $subset \
                --manifest-folder $manifest_dir
            touch $manifest_dir/.${subset}.done
        fi
    done
fi

if [ $stage -le 2 ] && [ $stop_stage -ge 2 ]; then
  log "State 2: Preprocess GigaSpeech manifest"
  if [ ! -f $fbank_dir/.preprocess_complete ]; then
   python3 ./local/preprocess_gigaspeech_hf.py
   touch $fbank_dir/.preprocess_complete
  fi
fi

if [ $stage -le 3 ] && [ $stop_stage -ge 3 ]; then
  log "Stage 3: Compute features for L, M, S, XS, DEV and TEST subsets of GigaSpeech."
  for subset in l; do
    python3 ./local/compute_fbank_gigaspeech.py \
        --manifest-dir $fbank_dir \
        --num-mel-bins 128 \
        --subset $subset
  done
fi

if [ $stage -le 4 ] && [ $stop_stage -ge 4 ]; then
  log "State 4: Preprocess GigaSpeech xl manifest"
  if [ ! -f $fbank_dir/.xl.preprocess_complete ]; then
   python3 ./local/preprocess_gigaspeech.py
   touch $fbank_dir/.xl.preprocess_complete
  fi
fi

if [ $stage -le 5 ] && [ $stop_stage -ge 5 ]; then
  log "Stage 5: Split xl subset into pieces (may take 30 minutes)"
  split_dir=${fbank_dir}/xl_split
  if [ ! -f $split_dir/.split_completed ]; then
    lhotse split-lazy $fbank_dir/gigaspeech_cuts_xl_raw.jsonl.gz $split_dir $num_per_split
    touch $split_dir/.split_completed
  fi
fi

if [ $stage -le 6 ] && [ $stop_stage -ge 6 ]; then
  log "Stage 6: Compute features for xl"
  num_splits=$(find ${fbank_dir}/xl_split -name "gigaspeech_cuts_xl_raw.*.jsonl.gz" | wc -l)
  python3 ./local/compute_fbank_gigaspeech_splits.py \
    --num-workers 20 \
    --batch-duration 600 \
    --start 250 \
    --stop 301 \
    --num-splits $num_splits \
    --num-mel-bins 128 \
    --fbank-dir $fbank_dir
fi

if [ $stage -le 7 ] && [ $stop_stage -ge 7 ]; then
  log "Stage 7: Combine features for XL (may take 3 hours)"
  if [ ! -f ${fbank_dir}/gigaspeech_cuts_xl.jsonl.gz ]; then
    pieces=$(find ${fbank_dir}/xl_split -name "gigaspeech_cuts_xl.*.jsonl.gz")
    lhotse combine $pieces $fbank_dir/gigaspeech_cuts_xl.jsonl.gz
  fi
fi